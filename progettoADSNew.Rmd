---
title: "Analisi bibliometrica - I docenti del DMIF"
author: "Claudia Costa - 153256"
date: "`r Sys.Date()`"
css: stileProgetto.css
output: 
  rmdformats::readthedown:
  highlight: kate
editor_options: 
  markdown: 
    wrap: 72
bibliography: references.bib
---

```{r setup, include=FALSE}
library(knitr)
library(rmdformats)
#knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
## Global options
options(max.print=2000)
knitr::opts_chunk$set(echo=FALSE,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

```{r img uniud, echo=FALSE}
htmltools::img(src = knitr::image_uri("dmif.png"), 
               alt = 'logo', 
               style = 'position:absolute; top:0; right:0; padding:10px;')
```

```{r caricamento librerie, include=FALSE}
library(bibliometrix)
library(dplyr)
library(ggplot2)
library(tidyverse) # Collection of all the good stuff like dplyr, ggplot2 ect.
library(magrittr) # For extra-piping operators (eg. %<>%)
library(data.table) # Good format to work with large datasets
library(skimr) # Nice descriptives
library(igraph) # Network analysis
library(tidygraph) # Tidy network analysis
library(ggraph) # ggplot-like nw plotting
library(Matrix)
library(purrr)
library(plotly)
library(htmltools)
library(multigraph)
library(wordcloud2)
library(wordcloud)
library(poweRlaw)
```

```{r script plot, include=FALSE}
source("plot.bibliometrix.R", local = knitr::knit_global())
# or sys.source("your-script.R", envir = knitr::knit_global())
```

```{r script plot2, include=FALSE}
source("authorProdOverTime.R", local = knitr::knit_global())
# or sys.source("your-script.R", envir = knitr::knit_global())
```

```{r script summary, include=FALSE}
source("summary.bibliometrix.R", local = knitr::knit_global())
# or sys.source("your-script.R", envir = knitr::knit_global())
```

```{r script zzz, include=FALSE}
source("zzz.R", local = knitr::knit_global())
# or sys.source("your-script.R", envir = knitr::knit_global())
```

```{r script histPlot, include=FALSE}
source("histPlot.R", local = knitr::knit_global())
# or sys.source("your-script.R", envir = knitr::knit_global())
```

```{r script networkPlot, include=FALSE}
source("networkPlot.R", local = knitr::knit_global())
# or sys.source("your-script.R", envir = knitr::knit_global())
```

```{r script networkStat, include=FALSE}
source("networkStat.R", local = knitr::knit_global())
# or sys.source("your-script.R", envir = knitr::knit_global())
```

```{r script hIndex, include=FALSE}
source("Hindex.R", local = knitr::knit_global())
# or sys.source("your-script.R", envir = knitr::knit_global())
```

# Introduzione

<!-- nuovo file con cose inutili tolte -->

<!-- uso file CSV filtrato con i docenti scelti a mano (serve la lista?), scaricati il 12/02/2024 (nuovo: 24/04/2024)
query usata su scopus: AF-ID ( "Universit&#224; degli Studi di Udine" 60025965 ) AND SUBJAREA ( comp ) AND ( LIMIT-TO ( PREFNAMEAUID , "Montanari, A.#7101889543" ) OR LIMIT-TO ( PREFNAMEAUID , "Chittaro, L.#7004119007" ) OR LIMIT-TO ( PREFNAMEAUID , "Mizzaro, S.#6603594721" ) OR LIMIT-TO ( PREFNAMEAUID , "Dovier, A.#6603827082" ) OR LIMIT-TO ( PREFNAMEAUID , "Policriti, A.#6701331312" ) OR LIMIT-TO ( PREFNAMEAUID , "Miculan, M.#6602346936" ) OR LIMIT-TO ( PREFNAMEAUID , "Piazza, C.#56228866500" ) OR LIMIT-TO ( PREFNAMEAUID , "Piciarelli, C.#9039137600" ) OR LIMIT-TO ( PREFNAMEAUID , "Fontana, F.#55970349500" ) OR LIMIT-TO ( PREFNAMEAUID , "Lancia, G.#6701584197" ) OR LIMIT-TO ( PREFNAMEAUID , "Formisano, A.#7003786950" ) OR LIMIT-TO ( PREFNAMEAUID , "Roitero, K.#57191042663" ) OR LIMIT-TO ( PREFNAMEAUID , "Scagnetto, I.#56242036400" ) OR LIMIT-TO ( PREFNAMEAUID , "Brajnik, G.#6603009854" ) OR LIMIT-TO ( PREFNAMEAUID , "Serra, G.#10140344600" ) OR LIMIT-TO ( PREFNAMEAUID , "Ranon, R.#6603216942" ) OR LIMIT-TO ( PREFNAMEAUID , "Franceschet, M.#6603459161" ) OR LIMIT-TO ( PREFNAMEAUID , "Mirolo, C.#6603641510" ) OR LIMIT-TO ( PREFNAMEAUID , "Della Mea, V.#7003376592" ) OR LIMIT-TO ( PREFNAMEAUID , "Buttussi, F.#16229748200" ) OR LIMIT-TO ( PREFNAMEAUID , "Geatti, L.#57204585138" ) OR LIMIT-TO ( PREFNAMEAUID , "D&apos;Agostino, G.#35617431600" ) OR LIMIT-TO ( PREFNAMEAUID , "Della Monica, D.#57195719517" ) OR LIMIT-TO ( PREFNAMEAUID , "Maddalena, E.#56382377600" ) OR LIMIT-TO ( PREFNAMEAUID , "Casagrande, A.#23395669600" ) OR LIMIT-TO ( PREFNAMEAUID , "Comini, G.#7005313868" ) OR LIMIT-TO ( PREFNAMEAUID , "Puppis, G.#6507419503" ) OR LIMIT-TO ( PREFNAMEAUID , "Mea, V.D.#7003376592" ) OR LIMIT-TO ( PREFNAMEAUID , "Soprano, M.#57203392311" ) OR LIMIT-TO ( PREFNAMEAUID , "Monica, D.D.#57195719517" ) OR LIMIT-TO ( PREFNAMEAUID , "Romanello, R.#57903048800" ) ) -->

```{r}
# uso file bib filtrato con i docenti scelti a mano, scaricati il 15/07/2024
#fileF <- "uniudFiltered (1).bib"
#fileF <- "scopus.txt"
#uniudFilt <- convert2df(file = fileF, dbsource = "scopus", format = "bibtex")
```

```{r caricamento file, include=FALSE}
fileCSV <- "scopus.csv"
#prova <- convert2df(file = fileCSV, dbsource = "scopus", format = "csv")
newProva <- convert2df(file = "scopusJuly.csv", dbsource = "scopus", format = "csv")
#M <- convert2df(file = fileCSV, dbsource = "scopus", format = "csv")
```

## Che cosa è la bibliometria?

La bibliometria è una disciplina che utilizza analisi quantitative e statistiche per analizzare le pubblicazioni scientifiche e le loro relazioni.

Il progetto si focalizza sull'analisi della produzione scientifica dei docenti del dipartimento DMIF dell'Università degli Studi di Udine, per cercare di dare una stima di:

- come collaborano gli autori

- quali sono i settori di maggiore interesse

- gli autori più prolifici.

Per supporto all'analisi è stata utilizzata una libreria, [Bibliometrix](https://www.bibliometrix.org/home/) [@bibliometrix], sviluppata da due docenti dell'Università di Napoli.

## Fonte dei dati

I dati analizzati in questo progetto sono stati scaricati (ultimo download: 15/07/2024) da
[Scopus](https://www.scopus.com/search/form.uri?display=basic&zone=header&origin=searchbasic#basic), uno dei principali dabatase bibliografici. E' stata selezionata la sotto area "computer science" e successivamente sono stati selezionati 31 autori del DMIF, tra docenti e dottorandi.

Ogni articolo del dataframe contiene svariati attributi tra cui: la lista di autori, il titolo del documento, la sorgente di pubblicazione, il tipo di documento, le parole chiavi degli autori, le references, il numero di citazioni e l'anno di pubblicazione.

# Analisi bibliometrica

## Analisi descrittiva del dataframe

La tabella delle informazioni principali descrive le dimensioni della
raccolta in termini di numero di documenti, numero di autori, numero di fonti, numero di parole chiave, durata e numero medio di citazioni.

- "docs per autori" è calcolato come rapporto tra il numero totale di autori e il numero totale di articoli.

- "co-autori per articolo" è calcolato come numero medio di co-autori per articolo.

```{r analisi descrittiva}
results <- biblioAnalysis(newProva, sep = ";")
options(width=100)
S <- summary(object = results, k = 10, pause = FALSE)
gs <- plot.bibliometrix(x = results, k = 10, pause = FALSE)

```


```{r}
ggplotly(gs$MostProdAuthors)
```
Autore più produttivo: Prof. Montanari con 200 articoli.

```{r}
ggplotly(gs$MostProdCountries)
#SCP: Single Country Publications
#MCP: Multiple Country Publications
```
Paese più produttivo: Italia.

```{r}
plot(gs$AnnualScientProd)
```

Anno più produttivo: 2023 con 87 pubblicazioni.

```{r}
plot(gs$AverArtCitperYear)
```

Anno con media citazioni in articoli più alta: 2018.

```{r}
plot(gs$AverTotCitperYear)
```

Anno con più citazioni: 1987.


### Documenti per tipo

```{r analisi docs}
newProva %>%
  count(DT, sort = TRUE)

docType <- ggplot(newProva) +
  geom_bar(mapping = aes(x = fct_infreq(DT), fill = DT)) +
  labs(x = "", y = "Number of documents", fill = "Type") +
  theme_bw() +
  theme(legend.position = "bottom", axis.text.x = element_text(angle = -60))

ggplotly(docType)
```

Tipo di pubblicazione più presente: conference paper, seguito da articoli e capitoli di libro.

## Analisi dei riferimenti citati

<!-- La funzione citazioni genera la tabella di frequenza dei riferimenti più citati o dei primi autori più citati (dei riferimenti). (nel senso, sono tutte le references degli articoli della collezione) -->

E' possibile analizzare la frequenza dei riferimenti/primi autori più citati nel dataset in analisi.

<!-- La citazione globale rappresenta il numero totale di citazioni ricevute da un documento da tutte le pubblicazioni indicizzate in una fonte - in questo caso il dataset in analisi. -->

Papers citati più frequentemente:
```{r analisi ref}
mostCitedRef <- citations(newProva, field = "article", sep = ";")
cbind(mostCitedRef$Cited[1:10])
```

Si noti che 2 articoli del Professor Montanari sono tra i più citati.

Primi autori citati più frequentemente:
```{r analisi ref aut}
mostCitedAut <- citations(newProva, field = "author", sep = ";")
cbind(mostCitedAut$Cited[1:15])
#cbind(CR$Cited[c(-2, 1:14)])
```

E' possibile notare che gli autori più frequentemente citati sono i Professori Montanari, Dovier, Mizzaro e Policriti.

## H-index degli autori

L'h-index è una metrica a livello di autore che cerca di misurare sia la produttività che l'impatto citazionale delle pubblicazioni.

L’indice si basa sull’insieme degli articoli più citati dello scienziato e sul numero di citazioni ricevute in altre pubblicazioni. L’indice è strutturato per quantificare mediante un singolo indice numerico non solo la produzione, ma anche l’influenza di uno scienziato, distinguendolo da chi ha pubblicato molti articoli ma di scarso interesse.

Quindi, uno scienziato ha un indice n se almeno n lavori tra quelli che ha pubblicato sono stati citati almeno n volte ciascuno.

L'i10-index consiste nel numero di pubblicazioni di uno stesso autore con almeno 10 citazioni.

<!-- L'indice è definito in modo tale che sull'insieme dato di articoli, ordinati in ordine decrescente di citazioni ricevute, il valore dell'indice-g è assegnato quando i primi g articoli hanno ricevuto cumulativamente $g^2$ citazioni.
$$g^2 \leq \sum_{i \leq g} c_i$$

L' M-index è definito come h/n, dove h è l' H-index e n è il numero di anni trascorsi dalla prima pubblicazione del ricercatore. -->

H-index dei primi 10 autori più produttivi (in questa raccolta):

```{r indice h}
authors=gsub(","," ",names(results$Authors)[1:10])

indicesAll <- Hindex(newProva, field = "author", elements=authors, sep = ";", years = 50)

slice(indicesAll$H, order(indicesAll$H$h_index, decreasing = TRUE))
```

Gli autori con l'H-index più alto sono i Prof. Chittaro (39), Prof. Montanari (23) e Prof. Mizzaro (20).


# Matrici di rete bibliografica

Gli attributi dei paper sono collegati tra loro attraverso il paper stesso: autore/i alla rivista, parole chiave alla data di pubblicazione, ecc. Alcune delle analisi descrittive viste in precedenza si possono visualizzare attraverso reti bipartite.


## Reti bipartite

Queste connessioni di diversi attributi generano reti bipartite che possono essere rappresentate come matrici rettangolari (Papers x Attributi).

Rete Paper x Fonte di pubblicazione:

```{r esempio bip}
manSource <- cocMatrix(newProva, Field = "SO", sep = ";", type = "matrix")
```

L'oggetto è una matrice binaria rettangolare che rappresenta una rete bipartita in cui le righe e le colonne sono, in questo caso, rispettivamente papers e fonti.

L'elemento generico $bip_{ij}$ è 1 se il paper $i$ è stato pubblicato nella fonte $j$, 0 altrimenti.

La somma della colonna $j$-esima $bip_j$ rappresenta il numero di papers pubblicati nella fonte $j$.

Fonti di pubblicazione più rilevanti:

```{r bip source}
sort(Matrix::colSums(manSource), decreasing = TRUE)[1:5]
```


Rete degli autori: Paper x Autore, conta quanti articoli fatti da autori.

```{r rete autori}
autNet <- cocMatrix(newProva, Field = "AU", sep = ";", type = "matrix")
sort(Matrix::colSums(autNet), decreasing = TRUE)[1:5]
```


## Accoppiamento bibliografico - autori

Le pubblicazioni scientifiche contengono riferimenti ad altri lavori scientifici. Questo genera un'altra rete, quella delle reti di accoppiamento o co-citazioni.

Due autori sono accoppiati bibliograficamente **se almeno una fonte citata compare nelle loro pubblicazioni**.
<!-- (papers A e B sono accoppiati bibliograficamente perchè hanno citato entrambi papers C, D, E) -->

Rete di accoppiamento: $$B = A\cdot A^T$$ dove A è una rete bipartita (Papers x Citazioni).  Due autori sono collegati da un arco nella rete se citano insieme uno o più documenti.

L'elemento $b_{i,j}$ indica quanti accoppiamenti bibliografici esistono tra $i$ e $j$. La forza dell'accoppiamento di due autori, $i$ e $j$, è definita dal numero di riferimenti che gli autori hanno in comune.

L'accoppiamento bibliografico tra autori è una misura di quanto due autori condividono riferimenti comuni nelle loro pubblicazioni. In altre parole, quanti autori citano gli stessi lavori nelle loro ricerche.

(Per comodità nella computazione e visualizzazione, vengono utilizzati soltanto i 40 nodi con il grado più alto).

```{r accoppiamento autori}
autCoupNet <- biblioNetwork(newProva, analysis = "coupling", network = "authors", sep = ";")
netCoup = networkPlot(autCoupNet,  normalize = "association", weighted=NULL, n = 40, Title = "Authors' Coupling", type = "auto", size.cex=TRUE, remove.multiple=TRUE, labelsize=2, label.n=40, label.cex=TRUE, label.color = TRUE, halo = FALSE)
# Convertire la rete di Bibliometrix in un oggetto igraph
g1 <- graph_from_adjacency_matrix(autCoupNet, mode = "undirected", diag = FALSE)
#d1 <- table(netCoup$nodeDegree)
#netCoup$nodeDegree
```

### Analisi della rete

I nodi più centrale della rete risultano essere il Professor Chittaro ed il Professor Montanari. Il primo ha i valori più alti nella centralità di betweenness e pagerank, mentre il secondo nella centralità di grado, di autovettore e closeness. ^[Tutte le nozioni viste a lezione sono utilizzate ma non ri-definite.].

```{r}
as_tbl_graph(g1) %>%
  activate(nodes) %>%
  mutate(degree = centrality_degree(normalized = TRUE), closeness = centrality_closeness(), betweenness = centrality_betweenness(normalized = TRUE), eigen = centrality_eigen()) %>%
  select(name, degree, closeness, betweenness, eigen) %>%
  arrange(desc(degree), desc(closeness), desc(betweenness), desc(eigen)) %>%
  slice(1:40) %>%
  as_tibble()
```


```{r net cluster centrality}
netCoup$cluster_res[1:10,]
```

```{r accop autori stat}
net <- graph.adjacency(autCoupNet,mode="undirected",weighted=NULL)
d1 <- table(degree(net))
#mean(degree(net))
#degree(net, v = V(net), mode = c("all"), loops = TRUE, normalized = TRUE)
#autCoupstat <- networkStat(autCoupNet, stat = "all")
#autCoupstat$network$networkCentrEigen
#summary(autCoupstat)
```

Numero di nodi: 
```{r}
vcount(net)
```

Densità:
```{r}
edge_density(net, loops = TRUE)
```
indica una rete densa, altamente collegata.

Transitività:
```{r}
transitivity(net, type="global")
```
rete poco clusterizzata.

<!-- Centralizzazione del grado: misura che valuta quanto una rete è centralizzata in base alla distribuzione del grado dei nodi. Se un singolo nodo ha un grado molto più alto rispetto a tutti gli altri, la centralizzazione del grado sarà alta. Se i gradi sono distribuiti più uniformemente tra i nodi, la centralizzazione del grado sarà bassa. 
Nel mio caso, vi sono alcuni nodi con un numero di collegamenti significativamente maggiore rispetto alla maggior parte degli altri nodi, ma la distribuzione dei gradi non è uguale.
 per essere uguale il valore deve essere 0 -->

Lunghezza media dei percorsi e diametro:
```{r}
mean_distance(net, directed=F)
diameter(net, directed=F, weights=NA)
```
molto breve, rete compatta e ben collegata.

Utilizzando la libreria poweRlaw, è possibile controllare se la mia distribuzione dei gradi segue una distribuzione power-law.

```{r}
# Crea un oggetto power-law
pl1 <- displ$new(d1)

# Adatta la legge di potenza ai dati
est1 <- estimate_xmin(pl1)

# Imposta xmin al valore stimato
pl1$setXmin(est1)

# Mostra i risultati dell'adattamento
#print(est)

# Plotta la distribuzione dei gradi e la legge di potenza adattata
plot(pl1)
lines(pl1, col = "red")

bs_p1 = bootstrap_p(pl1)
#bs_p1$p

```

I pallini indicano la mia distribuzione dei gradi mentre la linea rossa indica la power-law adattata ai miei dati.

Il p-value di `r bs_p1$p` indica che i miei dati sono compatibili con la distribuzione power-law, con pochi nodi altamente connessi (hub) e molti nodi con poche connessioni.

# Collaborazione autori

La rete di collaborazione scientifica è una rete in cui i nodi sono gli autori e i legami sono le coautorialità in articoli, in quanto quest'ultima è una delle forme più documentate di collaborazione scientifica (Glanzel, 2004).

Due autori sono collegati nella rete **se hanno collaborato insieme in un articolo**.

Una rete di collaborazione tra autori può essere ottenuta utilizzando la formulazione generale: $$AC=A^T \cdot A$$ dove A è una rete bipartita Papers x Autori.

L'elemento diagonale $ac_i$ è il numero di papers di cui il ricercatore $i$ è autore o coautore.

(Per comodità nella computazione e visualizzazione, vengono utilizzati soltanto i 30 nodi con il grado più alto).

```{r collaborazione aut}
autColl <- biblioNetwork(newProva, analysis = "collaboration", network = "authors", sep = ";")
autnetcoll = networkPlot(autColl,  normalize = "association", weighted=NULL, n = 30, Title = "Authors' Collaboration", type = "auto", size.cex=TRUE, remove.multiple=TRUE, labelsize=2, label.n=30, label.cex=TRUE, label.color = TRUE, halo = FALSE)
# Convertire la rete di Bibliometrix in un oggetto igraph
g <- graph_from_adjacency_matrix(autColl, mode = "undirected", diag = FALSE)

#autnetcoll$nodeDegree
```

## Analisi della rete

Sono presenti 4 clusters ed in ognuno di essi è presente almeno un nodo con dei valori alti di centralità, il che indica un ruolo di connessione e influenza all'interno del cluster.

- cluster 1: Prof. Chittaro e Prof. Serra

- cluster 2: Prof. Policriti e Prof. Dovier

- cluster 3: Prof. Montanari

- cluster 4: Prof. Mizzaro e Prof. Della Mea


```{r autnetcoll cluster centrality}
autnetcoll$cluster_res
```


```{r accop autori stat2}
net2 <- graph.adjacency(autColl,mode="undirected",weighted=NULL)
d2 <- table(degree(net2))
#mean(degree(net))
#degree(net, v = V(net), mode = c("all"), loops = TRUE, normalized = TRUE)
#autCoupstat <- networkStat(autCoupNet, stat = "all")
#autCoupstat$network$networkCentrEigen
#summary(autCoupstat)
```

Numero di nodi: 
```{r}
vcount(net2)
```

Densità:
```{r}
edge_density(net2, loops = TRUE)
```
indica una rete molto sparsa, poco collegata.

Transitività:
```{r}
transitivity(net2, type="global")
```
rete moderatamente clusterizzata.

Lunghezza media dei percorsi e diametro:
```{r}
mean_distance(net2, directed=F)
diameter(net2, directed=F, weights=NA)
```
breve, rete compatta e collegata.



```{r rete collab stat}
#collabStat <- networkStat(autColl, stat = "all")
#summary(collabStat)
```
<!-- Densità: molto bassa, indicando che la maggior parte dei possibili collegamenti tra i nodi non esiste.

Transitività: relativamente alta, suggerendo che se due nodi sono entrambi collegati a un terzo nodo, c'è una buona probabilità che siano collegati tra loro. Questo è tipico delle reti con comunità ben definite.

Centralizzazione del grado: non c'è un singolo nodo dominante che ha la maggior parte delle connessioni ma il valore vicino allo 0 indica che la distribuzione dei gradi è abbastanza simile.

Lunghezza media dei percorsi: breve, rete compatta e collegata. -->

Utilizzando la libreria poweRlaw, è possibile controllare se la mia distribuzione dei gradi segue una distribuzione power-law.

```{r}
# Crea un oggetto power-law
pl2 <- displ$new(d2)

# Adatta la legge di potenza ai dati
est2 <- estimate_xmin(pl2)

# Imposta xmin al valore stimato
pl2$setXmin(est2)

# Plotta la distribuzione dei gradi e la legge di potenza adattata
plot(pl2)
lines(pl2, col = "red")

bs_p2 = bootstrap_p(pl2)
#bs_p2$p

```

I pallini indicano la mia distribuzione dei gradi mentre la linea rossa indica la power-law adattata ai miei dati.

Il p-value di `r bs_p2$p` indica che i miei dati sono compatibili con la distribuzione power-law, con pochi nodi altamente connessi (hub) e molti nodi con poche connessioni.

### Power measure

```{r}
library(lpSolve)
library(lpSolveAPI)

make_incidence = function(g) {
  n = vcount(g)
  m = ecount(g)
  # get edges as a matrix
  E = get.edges(g, E(g))
  B = matrix(0, nrow = n, ncol = m)
  # build incidence matrix
  for (i in 1:m) {
    B[E[i,1], i] = 1
    B[E[i,2], i] = 1
  }  
  return(B)
}

regularify = function (g) {
  n = vcount(g)
  m = ecount(g)
  B = make_incidence(g)
  # objective function
  obj = rep(0, m + 1)
  # constraint matrix
  con = cbind(B, rep(-1, n))
  # direction of constraints
  dir = rep("=", n)
  # right hand side terms
  rhs = -degree(g)
  # solve the LP problem
  sol = lp("max", obj, con, dir, rhs)
  # get solution
  if (sol$status == 0) {
    s = sol$solution
    # weights
    w = s[1:m] + 1
    # weighted degree
    d = s[m+1]
  }
  # return the solution
  if (sol$status == 0) {
    return(list(weights = w, degree = d)) 
  }
  else {
    return(NULL)   
  }
}
```


```{r power measure, echo=FALSE, results = 'hide'}
library(igraph)

regularify(g)

power <- function(A, t) {
  n <- dim(A)[1]
  x0 <- rep(0, n)
  x1 <- rep(1, n)
  x2 <- rep(1, n)
  diff <- 1
  eps <- 1/10^t
  iter <- 0
  epsilon <- 1e-10  # Aggiungere un piccolo valore per evitare divisioni per zero

  while (diff > eps) {
    x0 <- x1
    x1 <- x2
    x2 <- (1 / (x2 + epsilon)) %*% A  # Aggiungere epsilon a x2 per evitare divisioni per zero
    diff <- sum(abs(x2 - x0))
    iter <- iter + 1
  }
  
  alpha <- ((1 / (x2 + epsilon)) %*% A[,1]) / x2[1]
  x2 <- sqrt(alpha) %*% x2
  return(list(vector = as.vector(x2), iter = iter))
}

powerIter <- function(A, t, max_iter = 1000) {
  n <- dim(A)[1]
  x0 <- rep(0, n)
  x1 <- rep(1, n)
  x2 <- rep(1, n)
  diff <- 1
  eps <- 1 / 10^t
  iter <- 0
  epsilon <- 1e-10  # Aggiungere un piccolo valore per evitare divisioni per zero
  
  while (diff > eps && iter < max_iter) {
    x0 <- x1
    x1 <- x2
    x2 <- (1 / (x2 + epsilon)) %*% A  # Aggiungere epsilon a x2 per evitare divisioni per zero
    diff <- sum(abs(x2 - x0))
    iter <- iter + 1
  }
  
  alpha <- ((1 / (x2 + epsilon)) %*% A[,1]) / x2[1]
  x2 <- sqrt(alpha) %*% x2
  return(list(vector = as.vector(x2), iter = iter))
}


power_optimized <- function(A, t) {
  n <- dim(A)[1]
  x <- rep(1, n)
  epsilon <- 1e-10  # Aggiungere un piccolo valore per evitare divisioni per zero
  iter <- 0
  max_iter <- 1000  # Limitare il numero massimo di iterazioni
  
  repeat {
    x_old <- x
    x <- (1 / (x + epsilon)) %*% A
    x <- as.vector(x)
    
    # Calcolare la differenza relativa
    diff <- sum(abs(x - x_old)) / sum(abs(x_old))
    
    iter <- iter + 1
    
    if (diff < 1/10^t || iter >= max_iter) break
  }
  
  alpha <- ((1 / (x + epsilon)) %*% A[,1]) / x[1]
  x <- sqrt(alpha) * x
  
  return(list(vector = x, iter = iter))
}


# Convertire la matrice di adiacenza in una matrice normale
A <- as.matrix(get.adjacency(g))

# Use diagonal perturbation perché la matrice non è regolare
Adj = as_adjacency_matrix(g)
I = diag(0.15, vcount(g))
(AI = Adj + I)

# Calcolare la misura di potenza
t_precision = 6  # Definire la precisione desiderata
power_result <- powerIter(A, t_precision)

power_values <- power_result$vector
num_iterations <- power_result$iter

#print(power_values)
#print(paste("Number of iterations:", num_iterations))

```


```{r}
author_names <- V(g)$name
author_power <- data.frame(Author = author_names, Power = power_values)
author_power <- author_power[order(-author_power$Power), ]
#print(author_power)

total_value <- sum(power_values)

percentage_values <- (power_values / total_value) * 100

author_names <- V(g)$name
author_power <- data.frame(Author = author_names, PowerPercentage = percentage_values)

author_power <- author_power[order(-author_power$PowerPercentage), ]

#head(author_power)
author_power[1:15, ]

#correlation <- cor(power_values, degree(g))
#print(correlation)

```

Analizzando la misura di potenza, la quale afferma che un nodo è potente se è connesso a nodi non potenti, si ricava che i nodi più potenti all'interno della rete delle collaborazioni sono il Prof. Miculan (13.8% del potere totale) e il Prof. Policriti (9.2% del potere totale).

<!-- Per ulteriore controllo, calcolo la correlazione tra il grado del nodo e il potere: 0.6162251; vuol dire che c'è una piccola correlazione. -->


# Analisi parole chiave

## Rete parole chiave

Rete Bipartita Papers x Keyword Scopus

Ogni paper ha associate delle parole chiave dal database di Scopus.

```{r rete keywords}
idNet <- cocMatrix(newProva, Field = "ID", sep = ";", type = "matrix")
parole <- sort(Matrix::colSums(idNet), decreasing = TRUE)[1:50]
#keyCount

keyword_data <- data.frame(
  word = names(parole),
  freq = parole
)

```

### Word cloud

Dai dati della rete bipartita è possibile creare un dataframe con le frequenze delle parole, da cui si può ricavare una word cloud.

```{r save wordcloud}
library(DT)
saveWidget(wordcloud2(data = keyword_data, size = .4), "wordCloud3.html")
```


```{r word cloud, echo=FALSE}
htmltools::tags$iframe(title = "Word Cloud", src = "wordCloud3.html")
```

Le tre parole più presenti sono Computer Circuits (125), Semantics (101) e Temporal Logic (99).

## Rete co-occorrenze parole chiave

(Per comodità nella computazione e visualizzazione, vengono utilizzati soltanto i 45 nodi con il grado più alto).

```{r rete cooc key}
coOc <- biblioNetwork(newProva, analysis = "co-occurrences", network = "keywords", sep = ";")
coOcNet = networkPlot(coOc,  normalize = "association", weighted=T, n = 45, Title = "Keywords Co-Occurrence", type = "auto", size.cex=TRUE, remove.multiple=TRUE, labelsize=2, label.n=40, label.cex=TRUE, label.color = TRUE, halo = FALSE)
degrees <- table(coOcNet$nodeDegree)
```


```{r}
#hist_data <- hist(degrees, breaks = 0:(max(degrees)+1), plot = FALSE)

#plot(hist_data$breaks[-1], hist_data$counts, log = "xy", type = "h", 
#     xlab = "Grado (log scale)", ylab = "Frequenza (log scale)", 
#     main = "Distribuzione dei Gradi con Assi Logaritmici")
```

<!-- (pr centrality: misura l'importanza di un nodo nella rete in base ai collegamenti in entrata da altri nodi. Un nodo con un valore alto è considerato più importante o influente.) -->

Ci sono 4 cluster di parole chiave:

- nel primo, il nodo più centrale secondo le metriche di betweenness e closeness è "Mobile Devices"; mentre "Algorithms" risulta il nodo con centralità di autovettore e PageRank più alto;

- nel secondo, "Computer Programming" è il nodo con betweenness e clonesess più alta, mentre "Computer Circuits" ha centralità di autovettore e PageRank più alto.

- nel terzo,

- nel quarto, 


```{r coOcNet cluster centrality}
coOcNet$cluster_res
```


```{r rete cooc stat}
#coOcStat <- networkStat(coOc, stat = "all", type = "all")
#summary(coOcStat)
```

<!-- Densità: molto bassa.

Transitività: relativamente bassa per la dimensione della rete, le parole chiave tendono a collegarsi a molte altre senza formare gruppi chiusi; riflette i sottogruppi di argomenti o temi che sono discussi insieme.

Lunghezza media dei percorsi: molto breve, rete compatta e collegata. -->


```{r accop autori stat3}
net3 <- graph.adjacency(coOc,mode="undirected",weighted=NULL)
d3 <- table(degree(net3))
#mean(degree(net))
#degree(net, v = V(net), mode = c("all"), loops = TRUE, normalized = TRUE)
#autCoupstat <- networkStat(autCoupNet, stat = "all")
#autCoupstat$network$networkCentrEigen
#summary(autCoupstat)
```

Numero di nodi: 
```{r}
vcount(net3)
```

Densità:
```{r}
edge_density(net3, loops = TRUE)
```
indica una rete molto sparsa, poco collegata.

Transitività:
```{r}
transitivity(net3, type="global")
```
rete poco clusterizzata.


Lunghezza media dei percorsi e diametro:
```{r}
mean_distance(net3, directed=F)
diameter(net3, directed=F, weights=NA)
```
molto breve, rete compatta e ben collegata.


Utilizzando la libreria poweRlaw, è possibile controllare se la mia distribuzione dei gradi segue una distribuzione power-law.


```{r}
# Crea un oggetto power-law
pl <- displ$new(degrees)

# Adatta la legge di potenza ai dati
est <- estimate_xmin(pl)

# Imposta xmin al valore stimato
pl$setXmin(est)

# Mostra i risultati dell'adattamento
#print(est)

# Plotta la distribuzione dei gradi e la legge di potenza adattata
plot(pl)
lines(pl, col = "red")

bs_p = bootstrap_p(pl)
#bs_p$p

```

I pallini indicano la mia distribuzione dei gradi mentre la linea rossa indica la power-law adattata ai miei dati.

Il p-value di `r bs_p$p` indica che i miei dati sono compatibili con la distribuzione power-law, con pochi nodi altamente connessi (hub) e molti nodi con poche connessioni.


## Mappa tematica

L'analisi di co-occorrenza delle parole chiave genera cluster tematici, la cui densità e centralità permettono di classificarli e mapparli in un diagramma bidimensionale, creando una mappa tematica. 

Essa consente di analizzare i temi in base al quadrante in cui sono collocati:

1. quadrante in alto a sinistra: temi molto specializzati/di nicchia (cluster molto denso e poco centrale);

2. quadrante in alto a destra: temi motori (cluster molto denso e molto centrale);

3. quadrante in basso a sinistra: temi emergenti o in via di estinzione (cluster poco denso e poco centrale);

4. quadrante in basso a destra: temi di base (cluster poco denso ma molto centrale).

```{r mappa tematica}
map <- thematicMap(newProva, field = "ID", n = 500, minfreq = 5)
plot(map$map)
#map$clusters
#map$words
```


Ad esempio, il cluster in cui spicca la parola "algorithms" è nel quadrante dei temi di base, mentre "crowdsourcing" si trova nel quadrante dei temi emergenti o in declino. Il cluster con "finite element method" si trova nel quadrante dei temi di nicchia.

La colonna n.rel si riferisce alle frequenze relative delle parole all'interno del cluster di appartenenza.

```{r cluster analysis}
clusters <-map$words %>%
  arrange(Cluster, desc(Occurrences))

clusters %>%
  select(Cluster, Words, Occurrences) %>%
  group_by(Cluster) %>%
  mutate(n.rel = Occurrences / sum(Occurrences) ) %>%
  slice(1:5)
```

# Conclusione FINIRE

L'analisi della produzione scientifica ha evidenziato diversi aspetti importanti, soprattutto attraverso l'analisi delle varie reti.

La rete dell'accoppiamento bibliografico tra autori ha mostrato come gli autori del dipartimento siano collegati tra loro attraverso le citazioni comuni, indicando una forte interconnessione tematica e la presenza di aree di ricerca ben definite e collaborazioni frequenti.

La rete di collaborazione tra autori ha rivelato la presenza di diversi cluster di collaborazione, con alcuni autori chiave che fungono da nodi centrali.

La rete delle co-occorrenze delle parole chiave ha messo in luce le principali aree di ricerca del dipartimento e le connessioni tematiche tra di esse. Alcune parole chiave emergono come particolarmente centrali e frequenti, riflettendo le aree di maggiore interesse e attività all'interno del dipartimento.

Inoltre, tutte le reti analizzate hanno la proprietà di piccolo mondo, con dei valori bassi di diametro e lunghezza media dei cammini e le tre distribuzioni di grado analizzate seguono una distribuzione dei gradi power-law.


In sintesi, si può dire che all'interno del dipartimento operano gruppi di ricerca che si distinguono per una notevole produttività scientifica, la quale si traduce in un significativo apporto alla letteratura di settore. Pur focalizzandosi su ambiti di ricerca differenti, i gruppi collaborano attivamente tra loro, favorendo lo scambio di conoscenze e competenze.
